{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70ea88d",
   "metadata": {},
   "source": [
    "#### Upload Data from S3 to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78363157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine, text\n",
    "import glob\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For display\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abb2c650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets loaded from S3 and inserted into PostgreSQL successfully.\n"
     ]
    }
   ],
   "source": [
    "# PostgreSQL Configuration\n",
    "db_params = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"sslmode\": os.getenv(\"DB_SSLMODE\")\n",
    "}\n",
    "\n",
    "\n",
    "# Load env credentials for PostgreSQL\n",
    "load_dotenv()\n",
    "\n",
    "db_url = (\n",
    "    f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@\"\n",
    "    f\"{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    ")\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "\n",
    "# --- S3 CONFIG (pandas + s3fs handles this internally) ---\n",
    "bucket = \"finriskai\"\n",
    "prefix = \"datasets/\"\n",
    "files = {\n",
    "    \"applications\": f\"s3://{bucket}/{prefix}credit_applications.csv\",\n",
    "    \"bureau\": f\"s3://{bucket}/{prefix}credit_bureau_data.csv\",\n",
    "    \"profiles\": f\"s3://{bucket}/{prefix}customer_profiles.csv\",\n",
    "    \"predictions\": f\"s3://{bucket}/{prefix}model_predictions.csv\",\n",
    "    \"transactions\": f\"s3://{bucket}/{prefix}transaction_data.csv\",\n",
    "}\n",
    "\n",
    "\n",
    "# READ DATA FROM S3 DIRECTLY INTO DATAFRAMES\n",
    "applications = pd.read_csv(files[\"applications\"], storage_options={\"anon\": False})\n",
    "bureau = pd.read_csv(files[\"bureau\"], storage_options={\"anon\": False})\n",
    "profiles = pd.read_csv(files[\"profiles\"], storage_options={\"anon\": False})\n",
    "predictions = pd.read_csv(files[\"predictions\"], storage_options={\"anon\": False})\n",
    "transactions = pd.read_csv(files[\"transactions\"], storage_options={\"anon\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24edaa",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "with engine.begin() as conn:\n",
    "    # Dimension: Customer Profiles\n",
    "    conn.execute(text(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dim_customer_profiles (\n",
    "        customer_id VARCHAR PRIMARY KEY,\n",
    "        customer_age INT,\n",
    "        annual_income NUMERIC(15,2),\n",
    "        employment_status VARCHAR,\n",
    "        account_tenure INT,\n",
    "        product_holdings INT,\n",
    "        relationship_value NUMERIC(15,2),\n",
    "        risk_segment VARCHAR,\n",
    "        behavioral_score NUMERIC(10,2),\n",
    "        credit_score INT,\n",
    "        city VARCHAR,\n",
    "        last_activity_date DATE\n",
    "    );\n",
    "    \"\"\"))\n",
    "\n",
    "    # Dimension: Bureau Data\n",
    "    conn.execute(text(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dim_bureau (\n",
    "        customer_id VARCHAR PRIMARY KEY,\n",
    "        credit_score INT,\n",
    "        credit_history_length INT,\n",
    "        number_of_accounts INT,\n",
    "        total_credit_limit NUMERIC(15,2),\n",
    "        credit_utilization NUMERIC(6,3),\n",
    "        payment_history NUMERIC(6,3),\n",
    "        public_records INT\n",
    "    );\n",
    "    \"\"\"))\n",
    "\n",
    "    # Fact: Applications\n",
    "    conn.execute(text(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS fact_applications (\n",
    "        application_id VARCHAR PRIMARY KEY,\n",
    "        customer_id VARCHAR REFERENCES dim_customer_profiles(customer_id),\n",
    "        application_date DATE,\n",
    "        loan_amount NUMERIC(15,2),\n",
    "        loan_purpose VARCHAR,\n",
    "        employment_status VARCHAR,\n",
    "        annual_income NUMERIC(15,2),\n",
    "        debt_to_income_ratio NUMERIC(6,3),\n",
    "        credit_score INT,\n",
    "        application_status VARCHAR,\n",
    "        default_flag INT\n",
    "    );\n",
    "    \"\"\"))\n",
    "\n",
    "    # Fact: Predictions\n",
    "    conn.execute(text(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS fact_predictions (\n",
    "        prediction_id VARCHAR PRIMARY KEY,\n",
    "        model_version VARCHAR,\n",
    "        customer_id VARCHAR REFERENCES dim_customer_profiles(customer_id),\n",
    "        prediction_date DATE,\n",
    "        prediction_type VARCHAR,\n",
    "        risk_score NUMERIC(10,2),\n",
    "        fraud_probability NUMERIC(6,3),\n",
    "        model_features JSONB,\n",
    "        prediction_explanation TEXT,\n",
    "        business_decision VARCHAR,\n",
    "        actual_outcome VARCHAR\n",
    "    );\n",
    "    \"\"\"))\n",
    "\n",
    "    # Fact: Transactions\n",
    "    conn.execute(text(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS fact_transactions (\n",
    "        transaction_id VARCHAR PRIMARY KEY,\n",
    "        customer_id VARCHAR REFERENCES dim_customer_profiles(customer_id),\n",
    "        transaction_date TIMESTAMP,\n",
    "        amount NUMERIC(15,2),\n",
    "        merchant_category VARCHAR,\n",
    "        transaction_type VARCHAR,\n",
    "        location VARCHAR,\n",
    "        device_info VARCHAR,\n",
    "        fraud_flag INT,\n",
    "        investigation_status VARCHAR\n",
    "    );\n",
    "    \"\"\"))\n",
    "\n",
    "\n",
    "    # --- UPLOAD DATA TO POSTGRES ---\n",
    "\n",
    "    applications.to_sql(\"fact_applications\", con=engine, if_exists=\"append\", index=False)\n",
    "    bureau.to_sql(\"dim_bureau\", con=engine, if_exists=\"append\", index=False)\n",
    "    profiles.to_sql(\"dim_customer_profiles\", con=engine, if_exists=\"append\", index=False)\n",
    "    predictions.to_sql(\"fact_predictions\", con=engine, if_exists=\"append\", index=False)\n",
    "    transactions.to_sql(\"fact_transactions\", con=engine, if_exists=\"append\", index=False)\n",
    "\n",
    "    print(\"All datasets loaded from S3 and inserted into PostgreSQL successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503dd56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
